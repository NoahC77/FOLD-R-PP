# FOLD-R-PP
The implementation of FOLD-R++ algorithm. The target of FOLD-R++ algorithm is to learn an answer set program for a classification task. Answer set programs are logic programs that permit negation of predicates and follow the stable model semantics for interpretation.

## Installation
### Prerequisites
The FOLD-R++ algorithm is developed with only python3. Numpy is the only dependency:

<code>
	python3 -m pip install numpy
	
</code>

## Instruction
### Data preparation

The FOLD-R++ algorithm takes tabular data as input, the first line for the tabular data should be the feature names of each column.
The FOLD-R++ algorithm does not have to encode the data for training. It can deal with numerical, categorical, and even mixed type features (one column contains both categorical and numerical values) directly.
However, the numerical features should be identified before loading the data, otherwise they would be dealt like categorical features (only literals with = and != would be generated).

There are many UCI example datasets that have been used to pre-populate the **data** directory. Code for preparing these datasets has already been added to datasets.py.


For example, the UCI breast-w dataset can be loaded with the following code:

<code>
	
    columns = ['clump_thickness', 'cell_size_uniformity', 'cell_shape_uniformity', 'marginal_adhesion',
    'single_epi_cell_size', 'bare_nuclei', 'bland_chromatin', 'normal_nucleoli', 'mitoses']
    nums = columns
    data, num_idx, columns = load_data('data/breastw/breastw.csv', attrs=columns, label=['label'], numerics=nums, pos='benign')
	
</code>

**columns** lists all the features needed, **nums** lists all the numerical features, **label** is the name of the output classification label, **pos** indicates the positive value of the label. For binary classification, the **label value with more examples** should be selected as positive.

### Training
The FOLD-R++ algorithm generates an explainable model that is represented by an answer set program for classification tasks. Here's a training example for breast-w dataset:

<code>
	
    X_train, Y_train = split_xy(data_train)
    X_pos, X_neg = split_X_by_Y(X_train, Y_train)
    rules1 = foldrpp(X_pos, X_neg, [])
	
</code>

The rules generated by foldrpp will be stored in **rlues1**. These rules are organized in a nested intermediate representation. So, next, we flatten and decode the nested rules to have them conform to the syntax of answer set programs: 

<code>
	
    fr1 = flatten(rules1)
    rule_set = decode_rules(fr1, attrs)
    for r in rule_set:
        print(r)
	
</code>

The training process is started with: 
<code>
	python3 main.py
</code>

An answer set program that is compatible with the s(CASP) system is generated as shown below. The s(CASP) system is a system for direclty executing predicate answer set programs in a query-driven manner.

<code>
	
	% breastw dataset (699, 10).
	% the answer set program generated by foldr++:
	
	label(X,'benign'):- bare_nuclei(X,'?').
	label(X,'benign'):- bland_chromatin(X,N6), N6=<4.0,
			    clump_thickness(X,N0), N0=<6.0,  
	                    bare_nuclei(X,N5), N5=<1.0, not ab7(X).   
	label(X,'benign'):- cell_size_uniformity(X,N1), N1=<2.0,
			    not ab3(X), not ab5(X), not ab6(X).  
	label(X,'benign'):- cell_size_uniformity(X,N1), N1=<4.0,
			    bare_nuclei(X,N5), N5=<3.0,
			    clump_thickness(X,N0), N0=<3.0, not ab8(X).  
	ab2(X):- clump_thickness(X,N0), N0=<1.0.  
	ab3(X):- bare_nuclei(X,N5), N5>5.0, not ab2(X).  
	ab4(X):- cell_shape_uniformity(X,N2), N2=<1.0.  
	ab5(X):- clump_thickness(X,N0), N0>7.0, not ab4(X).  
	ab6(X):- bare_nuclei(X,N5), N5>4.0, single_epi_cell_size(X,N4), N4=<1.0.  
	ab7(X):- marginal_adhesion(X,N3), N3>4.0.  
	ab8(X):- marginal_adhesion(X,N3), N3>6.0.  
	
	% foldr++ costs:  0:00:00.027710  post: 0:00:00.000127
	% acc 0.95 p 0.96 r 0.9697 f1 0.9648 
	
</code>

### Testing in Python
Given **X_test**, a list of test data samples, the Python **predict** function will predict the classification outcome for each of these data samples. 

<code>
	Y_test_hat = predict(rules1, X_test)

</code>

The **classify** function can also be used to classify a single data sample.
	
<code>
	y_test_hat = classify(rules1, x_test)

</code>

### Justification by using s(CASP)
Classification and its justification can be conducted with the s(CASP) system. However, each data sample needs to be converted into predicate format that the s(CASP) system expects. The **decode_test_data** function can be used for this conversion.

<code>
	
	data_pred = decode_test_data(data_test, attrs)
	for p in data_pred:
	    print(p)
</code>

Here is an example of the answer set program generated for the acute dataset by FOLD-R++, along with 3 test data samples converted into the predicate format.

<code>
	
	% acute dataset (120, 7) 
	% the answer set program generated by foldr++:

	ab2(X):- a5(X,'no'), a1(X,N0), N0>37.9.
	label(X,'yes'):- not a4(X,'no'), not ab2(X).

	% foldr++ costs:  0:00:00.001990  post: 0:00:00.000040
	% acc 1.0 p 1.0 r 1.0 f1 1.0 

	id(1).
	a1(1,37.2).
	a2(1,'no').
	a3(1,'yes').
	a4(1,'no').
	a5(1,'no').
	a6(1,'no').

	id(2).
	a1(2,38.1).
	a2(2,'no').
	a3(2,'yes').
	a4(2,'yes').
	a5(2,'no').
	a6(2,'yes').

	id(3).
	a1(3,37.5).
	a2(3,'no').
	a3(3,'no').
	a4(3,'yes').
	a5(3,'yes').
	a6(3,'yes').

</code>

### s(CASP)

All the resources of s(CASP) can be found at https://gitlab.software.imdea.org/ciao-lang/sCASP.

## Citation

<code>
	
	@misc{wang2021foldr,
	      title={FOLD-R++: A Toolset for Automated Inductive Learning of Default Theories from Mixed Data}, 
	      author={Huaduo Wang and Gopal Gupta},
	      year={2021},
	      eprint={2110.07843},
	      archivePrefix={arXiv},
	      primaryClass={cs.LG}
	}

</code>
